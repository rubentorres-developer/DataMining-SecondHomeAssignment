{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "333368e3-bb42-466c-8823-c45ed71f970f",
   "metadata": {},
   "source": [
    "# Prospecção de Dados (Data Mining) DI/FCUL - HA2\n",
    "\n",
    "## Second Home Assignement (MC/DI/FCUL - 2024)\n",
    "\n",
    "### Fill in the section below\n",
    "\n",
    "### GROUP:`02`\n",
    "\n",
    "* João Martins, 62532 - Hours worked on the project: 8k\n",
    "* Rúben Torres, 62531 - Hours worked on the project: 8k\n",
    "* Nuno Pereira, 56933 - Hours worked on the project: 8k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ae0373-c651-4cfe-b4a4-42e9db6bd7e6",
   "metadata": {},
   "source": [
    "\n",
    "## Objectives\n",
    "The purpose of this Home Assignment is:\n",
    "\n",
    "1. Analyze the itemset/rules generation procedure\n",
    "2. Process and identify the most relevant rules\n",
    "\n",
    "**NOTE 1: Students are not allowed to add more cells to the notebook**\n",
    "\n",
    "**NOTE 2: The notebook must be submited fully executed**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a40f24-0da5-4b96-90f3-84259cbd1bc5",
   "metadata": {},
   "source": [
    "### 1. Read the Dataset\n",
    "\n",
    "Dataset: Instacart [Market Basket Analysis](https://www.kaggle.com/datasets/psparks/instacart-market-basket-analysis)\n",
    "\n",
    "\n",
    "\n",
    "The purpose of this Home Assignment is:\n",
    "\n",
    "1. Analyze the itemset/rules generation procedure\n",
    "2. Identify the most relevant rules\n",
    "\n",
    "Please download the HA files from this moodle folder and inspect it like this:\n",
    "\n",
    "**NOTE 1: Students are not allowed to add more cells to the notebook**\n",
    "\n",
    "**NOTE 2: The notebook must be submited fully executed**\n",
    "\n",
    "The dataset has been preprocessed with transactions as lists of integers. It is necessary a decoder to see the actual products bought together\n",
    "\n",
    "Uncompress the data set (zip file) which will produce 2 files:\n",
    "* `order_products.pickle` a Python pickle with all the trasactions\n",
    "* A `products.txt` - decoder table with all the data relative to each item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ae8af3-04f6-49ce-a093-0f5cc1dcc26c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Read product names and IDs\n",
    "lines=open(\"products.txt\", \"rt\", encoding=\"utf8\").readlines()\n",
    "products=[0]*len(lines)\n",
    "for lin in lines[1:]:\n",
    "    pid, pname, aid, did=lin.strip().split(\"\\t\")    \n",
    "    products[int(pid)]=pname\n",
    "    \n",
    "#read transactions\n",
    "import pickle\n",
    "orders=pickle.load(open(\"order_products.pickle\", \"rb\"))\n",
    "\n",
    "#check names of products on transaction 2 (example):\n",
    "print(\"Transaction 2 is\", orders[2])\n",
    "for prod in orders[2]: print(\"Code: %5d is product: %s\" %(prod, products[prod]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73946fe0-a7ee-4554-87f5-6c8efc3a275f",
   "metadata": {},
   "source": [
    "### Objective 1 - Analyze the itemset/rules generation procedure\n",
    "\n",
    "1. From the approaches used in classes make a performance analysis up to a threshold level of support\n",
    "2. Define a good support threshold for analysis according to your computational capabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de744174-1989-42af-9e78-0948ea801ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add supporting functions here\n",
    "from scipy.sparse import csr_matrix\n",
    "from IPython.display import display_html\n",
    "from itertools import chain,cycle\n",
    "\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, fpgrowth\n",
    "from pyfim import pyeclat\n",
    "from PD_freqitems import freqitemsets\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "def display_side_by_side(*args,titles=cycle([''])):\n",
    "    html_str=''\n",
    "    for df,title in zip(args, chain(titles,cycle(['</br>'])) ):\n",
    "        html_str+='<th style=\"text-align:center\"><td style=\"vertical-align:top\">'\n",
    "        html_str+=f'<h2 style=\"text-align: center;\">{title}</h2>'\n",
    "        html_str+=df.to_html().replace('table','table style=\"display:inline\"')\n",
    "        html_str+='</td></th>'\n",
    "    display_html(html_str,raw=True)\n",
    "\n",
    "def plot_execution_time(D):\n",
    "    plt.plot(np.log(D[\"num_itemsets\"]), np.log(D[\"apriori\"]), c=\"r\", label=\"apriori\")\n",
    "    plt.plot(np.log(D[\"num_itemsets\"]), np.log(D[\"FP-growth\"]), c=\"k\", label=\"fp-growth\")\n",
    "    plt.plot(np.log(D[\"num_itemsets\"]), np.log(D[\"ECLAT\"]), c=\"g\", label=\"eclat\")\n",
    "    plt.plot(np.log(D[\"num_itemsets\"]), np.log(D[\"PD\"]), c=\"b\", label=\"PD\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "################################################################\n",
    "#Compute binary database\n",
    "tr_enc = TransactionEncoder()\n",
    "trans_array = tr_enc.fit_transform(orders.values(), sparse=True)\n",
    "trans_array = csr_matrix(trans_array, shape=(len(orders.values()), len(tr_enc.columns_)))\n",
    "\n",
    "products_list = []\n",
    "for i in range(len(tr_enc.columns_)+1):\n",
    "    products_list.append(products[i])\n",
    "\n",
    "products_list.pop(0)\n",
    "binary_database = pd.DataFrame.sparse.from_spmatrix(trans_array, columns=products_list)\n",
    "\n",
    "\n",
    "########################################################################################################\n",
    "# MemoryError: Unable to allocate 149. GiB for an array with shape (3214874, 49677) and data type bool #\n",
    "########################################################################################################\n",
    "\n",
    "# tr_enc = TransactionEncoder()\n",
    "# trans_array = tr_enc.fit(orders.values()).transform(orders.values())\n",
    "# products_list = []\n",
    "# for i in range(len(tr_enc.columns_)+1):\n",
    "#     products_list.append(products[i])\n",
    "# binary_database = pd.DataFrame(trans_array, columns=tr_enc.columns_)\n",
    "# binary_database\n",
    "\n",
    "################################################################\n",
    "\n",
    "binary_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e664c47-38e6-41dc-b5b3-c2c43f033cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add processing code here\n",
    "\n",
    "# FI_apriori = apriori(binary_database, min_support=0.01, use_colnames=True)\n",
    "# FI_apriori_len = FI_apriori.copy()\n",
    "\n",
    "# FI_apriori_len['length'] = FI_apriori_len['itemsets'].apply(lambda x: len(x))\n",
    "# FI_apriori_len = FI_apriori_len.sort_values(by=['length'], ascending=False)\n",
    "\n",
    "\n",
    "FI_fpg=fpgrowth(binary_database, min_support=0.01, use_colnames=True)\n",
    "FI_fpg\n",
    "\n",
    "FI_fpg['length'] = FI_fpg['itemsets'].apply(lambda x: len(x))\n",
    "FI_fpg.sort_values(by=['length'], ascending=False)\n",
    "\n",
    "FI_eclat= pyeclat(orders.values(), 0.01)\n",
    "FI_eclat\n",
    "\n",
    "FI_FI_fpg_filtered = FI_fpg[ (FI_fpg['support'] >= 0.01) & (FI_fpg['length'] >= 2) ]\n",
    "FI_FI_fpg_filtered\n",
    "\n",
    "# display_side_by_side(FI_fpg, FI_eclat)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "D={\"threshold\": [0.05, 0.02, 0.015], # 0.01\n",
    "\"num_itemsets\": [],\n",
    "\"apriori\":[],\n",
    "\"FP-growth\": [],\n",
    "\"ECLAT\": [],\n",
    "\"PD\": []}\n",
    "\n",
    "#WARNING! 0.01 sometimes crashes my computer it may well crash yours!\n",
    "for min_supp in D[\"threshold\"]:\n",
    "    t0 = time.time()\n",
    "    FI_apriori=apriori(binary_database, min_supp)\n",
    "    t1 = time.time()\n",
    "    D[\"num_itemsets\"].append(FI_apriori.shape[0])\n",
    "    D[\"apriori\"].append(t1-t0)\n",
    "\n",
    "    FI_fpg= fpgrowth(binary_database, min_supp)\n",
    "    t2 = time.time()\n",
    "\n",
    "    D[\"FP-growth\"].append(t2-t1)\n",
    "\n",
    "    FI_eclat= pyeclat(orders.values(), min_supp)\n",
    "    t3 = time.time()\n",
    "    D[\"ECLAT\"].append(t3-t2)\n",
    "\n",
    "    FI_pdfis= freqitemsets(orders.values(), min_supp)\n",
    "    t4 = time.time()\n",
    "    D[\"PD\"].append(t4-t3)\n",
    "\n",
    "    print(min_supp, FI_apriori.shape[0],\"\\n\\tApriori time:\", t1-t0,\n",
    "                                        \"\\n\\tFP-growth time:\", t2-t1,\n",
    "                                        \"\\n\\tECLAT time:\", t3-t2,\n",
    "                                        \"\\n\\tPD time:\", t4-t3)\n",
    "\n",
    "df_performance=pd.DataFrame(D)\n",
    "df_performance\n",
    "\n",
    "plot_execution_time(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a016c52-c66e-4499-8233-5631923eb695",
   "metadata": {},
   "source": [
    "### Your short analysis here\n",
    "\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853614f3-1e1b-4481-9784-e29dd0b453cb",
   "metadata": {},
   "source": [
    "### Objective 2 - Identify the most relevant rules\n",
    "\n",
    "1. From your predefined support level generate all available itemsets and generate rules\n",
    "2. Identify a set of 10 relevant rules using the Highest Lift criterion\n",
    "    * **NOTE**: Present the rules with the product names and not as Integers \n",
    "3. Identify the Maximal and Closed Itemsets for the same level of support and generate 5 rules using the Highest Lift\n",
    "    * **NOTE**: Do not list the Maximal or Closed Itemsets. Present just a few as an example and mention **how many** Closed and Maximal Itemsets were found for the selected support level\n",
    "    * **NOTE**: Present the rules with the product names and not as Integers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead806d9-8073-4fc0-9668-68ad0b89077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add supporting functions here\n",
    "\n",
    "from mlxtend.frequent_patterns import association_rules, fpmax\n",
    "\n",
    "all_rules = association_rules(FI_fpg, metric=\"confidence\", min_threshold=0.05)\n",
    "all_rules\n",
    "\n",
    "\n",
    "\n",
    "FI_fpmax=fpmax(binary_database, min_support=0.01, use_colnames=True)\n",
    "FI_fpmax\n",
    "\n",
    "\n",
    "\n",
    "Trans_maximal = pyeclat(orders.values(), 0.01, target=\"m\")\n",
    "print(\"Number of Maximal Itemsets\", len(Trans_maximal) )\n",
    "Trans_maximal\n",
    "\n",
    "\n",
    "Trans_closed = pyeclat(binary_database, 0.01, target=\"c\")\n",
    "print(\"Number of Closed Itemsets\", len(Trans_closed))\n",
    "Trans_closed\n",
    "\n",
    "# display_side_by_side(all_rules, FI_fpmax, Trans_maximal, Trans_closed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999f0f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7bf182",
   "metadata": {},
   "outputs": [],
   "source": [
    "FI_fpmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c83e5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Trans_maximal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a7f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Trans_closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad80328c-ffba-4bb6-8ce3-03726ee82348",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add processing code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322a87b8-4102-43ff-ac7c-e748df7bcd1f",
   "metadata": {},
   "source": [
    "### Your short analysis here\n",
    "\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
