{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "333368e3-bb42-466c-8823-c45ed71f970f",
   "metadata": {},
   "source": [
    "# Prospecção de Dados (Data Mining) DI/FCUL - HA2\n",
    "\n",
    "## Second Home Assignement (MC/DI/FCUL - 2024)\n",
    "\n",
    "### Fill in the section below\n",
    "\n",
    "### GROUP:`02`\n",
    "\n",
    "* João Martins, 62532 - Hours worked on the project: 8k\n",
    "* Rúben Torres, 62531 - Hours worked on the project: 8k\n",
    "* Nuno Pereira, 56933 - Hours worked on the project: 8k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ae0373-c651-4cfe-b4a4-42e9db6bd7e6",
   "metadata": {},
   "source": [
    "\n",
    "## Objectives\n",
    "The purpose of this Home Assignment is:\n",
    "\n",
    "1. Analyze the itemset/rules generation procedure\n",
    "2. Process and identify the most relevant rules\n",
    "\n",
    "**NOTE 1: Students are not allowed to add more cells to the notebook**\n",
    "\n",
    "**NOTE 2: The notebook must be submited fully executed**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a40f24-0da5-4b96-90f3-84259cbd1bc5",
   "metadata": {},
   "source": [
    "### 1. Read the Dataset\n",
    "\n",
    "Dataset: Instacart [Market Basket Analysis](https://www.kaggle.com/datasets/psparks/instacart-market-basket-analysis)\n",
    "\n",
    "\n",
    "\n",
    "The purpose of this Home Assignment is:\n",
    "\n",
    "1. Analyze the itemset/rules generation procedure\n",
    "2. Identify the most relevant rules\n",
    "\n",
    "Please download the HA files from this moodle folder and inspect it like this:\n",
    "\n",
    "**NOTE 1: Students are not allowed to add more cells to the notebook**\n",
    "\n",
    "**NOTE 2: The notebook must be submited fully executed**\n",
    "\n",
    "The dataset has been preprocessed with transactions as lists of integers. It is necessary a decoder to see the actual products bought together\n",
    "\n",
    "Uncompress the data set (zip file) which will produce 2 files:\n",
    "* `order_products.pickle` a Python pickle with all the trasactions\n",
    "* A `products.txt` - decoder table with all the data relative to each item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8ae8af3-04f6-49ce-a093-0f5cc1dcc26c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction 2 is [33120, 28985, 9327, 45918, 30035, 17794, 40141, 1819, 43668]\n",
      "Code: 33120 is product: Organic Egg Whites\n",
      "Code: 28985 is product: Michigan Organic Kale\n",
      "Code:  9327 is product: Garlic Powder\n",
      "Code: 45918 is product: Coconut Butter\n",
      "Code: 30035 is product: Natural Sweetener\n",
      "Code: 17794 is product: Carrots\n",
      "Code: 40141 is product: Original Unflavored Gelatine Mix\n",
      "Code:  1819 is product: All Natural No Stir Creamy Almond Butter\n",
      "Code: 43668 is product: Classic Blend Cole Slaw\n"
     ]
    }
   ],
   "source": [
    "#Read product names and IDs\n",
    "lines=open(\"products.txt\", \"rt\", encoding=\"utf8\").readlines()\n",
    "products=[0]*len(lines)\n",
    "for lin in lines[1:]:\n",
    "    pid, pname, aid, did=lin.strip().split(\"\\t\")    \n",
    "    products[int(pid)]=pname\n",
    "    \n",
    "#read transactions\n",
    "import pickle\n",
    "orders=pickle.load(open(\"order_products.pickle\", \"rb\"))\n",
    "\n",
    "#check names of products on transaction 2 (example):\n",
    "print(\"Transaction 2 is\", orders[2])\n",
    "for prod in orders[2]: print(\"Code: %5d is product: %s\" %(prod, products[prod]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73946fe0-a7ee-4554-87f5-6c8efc3a275f",
   "metadata": {},
   "source": [
    "### Objective 1 - Analyze the itemset/rules generation procedure\n",
    "\n",
    "1. From the approaches used in classes make a performance analysis up to a threshold level of support\n",
    "2. Define a good support threshold for analysis according to your computational capabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de744174-1989-42af-9e78-0948ea801ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add supporting functions here\n",
    "from scipy.sparse import csr_matrix\n",
    "from IPython.display import display_html\n",
    "from itertools import chain,cycle\n",
    "\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, fpgrowth\n",
    "from pyfim import pyeclat\n",
    "from PD_freqitems import freqitemsets\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "def display_side_by_side(*args,titles=cycle([''])) -> None:\n",
    "    html_str: str=''\n",
    "    for df,title in zip(args, chain(titles,cycle(['</br>'])) ):\n",
    "        html_str+='<th style=\"text-align:center\"><td style=\"vertical-align:top\">'\n",
    "        html_str+=f'<h2 style=\"text-align: center;\">{title}</h2>'\n",
    "        html_str+=df.to_html().replace('table','table style=\"display:inline\"')\n",
    "        html_str+='</td></th>'\n",
    "    display_html(html_str,raw=True)\n",
    "\n",
    "def plot_execution_time(Dict: dict) -> None:\n",
    "    plt.plot(np.log(Dict[\"num_itemsets\"]), np.log(Dict[\"apriori\"]), c=\"r\", label=\"apriori\")\n",
    "    plt.plot(np.log(Dict[\"num_itemsets\"]), np.log(Dict[\"FP-growth\"]), c=\"k\", label=\"fp-growth\")\n",
    "    plt.plot(np.log(Dict[\"num_itemsets\"]), np.log(Dict[\"ECLAT\"]), c=\"g\", label=\"eclat\")\n",
    "    plt.plot(np.log(Dict[\"num_itemsets\"]), np.log(Dict[\"PD\"]), c=\"b\", label=\"PD\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def compute_binary_encoder(products, orders) -> pd:\n",
    "    tr_enc = TransactionEncoder()\n",
    "    trans_array = tr_enc.fit_transform(orders.values(), sparse=True)\n",
    "    trans_array = csr_matrix(trans_array, shape=(len(orders.values()), len(tr_enc.columns_)))\n",
    "\n",
    "    products_list = []\n",
    "    for i in range(len(tr_enc.columns_)+1):\n",
    "        products_list.append(products[i])\n",
    "\n",
    "    products_list.pop(0)\n",
    "    return pd.DataFrame.sparse.from_spmatrix(trans_array, columns=products_list)\n",
    "\n",
    "\n",
    "################################################################\n",
    "# Compute binary database\n",
    "def test_minimum_support(binary_database: pd, Dict: dict) -> dict:\n",
    "    for min_supp in Dict[\"threshold\"]:\n",
    "        t0 = time.time()\n",
    "        FI_apriori=apriori(binary_database, min_supp)\n",
    "        t1 = time.time()\n",
    "        \n",
    "        Dict[\"num_itemsets\"].append(FI_apriori.shape[0])\n",
    "        Dict[\"apriori\"].append(t1-t0)\n",
    "\n",
    "        FI_fpg= fpgrowth(binary_database, min_supp)\n",
    "        t2 = time.time()\n",
    "\n",
    "        Dict[\"FP-growth\"].append(t2-t1)\n",
    "\n",
    "        FI_eclat= pyeclat(orders.values(), min_supp)\n",
    "        t3 = time.time()\n",
    "        Dict[\"ECLAT\"].append(t3-t2)\n",
    "\n",
    "        FI_pdfis= freqitemsets(orders.values(), min_supp)\n",
    "        t4 = time.time()\n",
    "        Dict[\"PD\"].append(t4-t3)\n",
    "\n",
    "        print(min_supp, FI_apriori.shape[0],\"\\n\\tApriori time:\", t1-t0,\n",
    "                                            \"\\n\\tFP-growth time:\", t2-t1,\n",
    "                                            \"\\n\\tECLAT time:\", t3-t2,\n",
    "                                            \"\\n\\tPD time:\", t4-t3)\n",
    "    return Dict\n",
    "\n",
    "########################################################################################################\n",
    "# MemoryError: Unable to allocate 149. GiB for an array with shape (3214874, 49677) and data type bool #\n",
    "########################################################################################################\n",
    "\n",
    "# binary_database = compute_binary_encoder(products, orders)\n",
    "# binary_database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e664c47-38e6-41dc-b5b3-c2c43f033cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaom\\AppData\\Local\\Temp\\ipykernel_10164\\3173793044.py:45: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  return pd.DataFrame.sparse.from_spmatrix(trans_array, columns=products_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09 2 \n",
      "\tApriori time: 1.0774493217468262 \n",
      "\tFP-growth time: 8.94369387626648 \n",
      "\tECLAT time: 46.03245687484741 \n",
      "\tPD time: 22.58569073677063\n",
      "0.05 6 \n",
      "\tApriori time: 1.294785976409912 \n",
      "\tFP-growth time: 9.435704946517944 \n",
      "\tECLAT time: 44.74222683906555 \n",
      "\tPD time: 22.01999068260193\n",
      "0.02 39 \n",
      "\tApriori time: 13.196900606155396 \n",
      "\tFP-growth time: 13.507108688354492 \n",
      "\tECLAT time: 51.46395421028137 \n",
      "\tPD time: 30.613744735717773\n",
      "0.015 69 \n",
      "\tApriori time: 118.02904391288757 \n",
      "\tFP-growth time: 23.64896035194397 \n",
      "\tECLAT time: 59.40992999076843 \n",
      "\tPD time: 40.03378629684448\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Add processing code here\n",
    "### 9 min execution\n",
    "\n",
    "binary_database = compute_binary_encoder(products, orders)\n",
    "\n",
    "FI_apriori = apriori(binary_database, min_support=0.02, use_colnames=False)\n",
    "FI_apriori_len = FI_apriori.copy()\n",
    "\n",
    "FI_apriori_len['length'] = FI_apriori_len['itemsets'].apply(lambda x: len(x))\n",
    "FI_apriori_len = FI_apriori_len.sort_values(by=['length'], ascending=False)\n",
    "\n",
    "\n",
    "FI_fpg = fpgrowth(binary_database, min_support=0.02, use_colnames=False)\n",
    "FI_fpg\n",
    "\n",
    "FI_fpg['length'] = FI_fpg['itemsets'].apply(lambda x: len(x))\n",
    "FI_fpg.sort_values(by=['length'], ascending=False)\n",
    "\n",
    "FI_eclat = pyeclat(orders.values(), supp=0.02)\n",
    "FI_eclat\n",
    "\n",
    "FI_FI_fpg_filtered = FI_fpg[(FI_fpg['support'] >= 0.01) & (FI_fpg['length'] >= 2)]\n",
    "FI_FI_fpg_filtered\n",
    "\n",
    "\n",
    "# display_side_by_side(FI_apriori, FI_fpg, FI_eclat)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Dict={\"threshold\": [0.09, 0.05, 0.02, 0.015], # 0.01\n",
    "\"num_itemsets\": [],\n",
    "\"apriori\":[],\n",
    "\"FP-growth\": [],\n",
    "\"ECLAT\": [],\n",
    "\"PD\": []}\n",
    "\n",
    "#WARNING! 0.01 sometimes crashes my computer it may well crash yours!\n",
    "\n",
    "Dict = test_minimum_support(binary_database, Dict)\n",
    "\n",
    "df_performance=pd.DataFrame(Dict)\n",
    "df_performance\n",
    "\n",
    "plot_execution_time(Dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a016c52-c66e-4499-8233-5631923eb695",
   "metadata": {},
   "source": [
    "### Your short analysis here\n",
    "\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853614f3-1e1b-4481-9784-e29dd0b453cb",
   "metadata": {},
   "source": [
    "### Objective 2 - Identify the most relevant rules\n",
    "\n",
    "1. From your predefined support level generate all available itemsets and generate rules\n",
    "2. Identify a set of 10 relevant rules using the Highest Lift criterion\n",
    "    * **NOTE**: Present the rules with the product names and not as Integers \n",
    "3. Identify the Maximal and Closed Itemsets for the same level of support and generate 5 rules using the Highest Lift\n",
    "    * **NOTE**: Do not list the Maximal or Closed Itemsets. Present just a few as an example and mention **how many** Closed and Maximal Itemsets were found for the selected support level\n",
    "    * **NOTE**: Present the rules with the product names and not as Integers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ead806d9-8073-4fc0-9668-68ad0b89077f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      support        itemsets  length\n",
      "104  0.016609  (24848, 47755)       2\n",
      "99   0.011862  (21899, 21133)       2\n",
      "94   0.019170  (13172, 21133)       2\n",
      "96   0.012599  (27960, 13172)       2\n",
      "97   0.019391  (13172, 47198)       2\n",
      "..        ...             ...     ...\n",
      "32   0.017259         (21934)       1\n",
      "31   0.075251         (21899)       1\n",
      "30   0.022654         (21612)       1\n",
      "29   0.082331         (21133)       1\n",
      "52   0.027880         (28198)       1\n",
      "\n",
      "[105 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>zhangs_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(24848)</td>\n",
       "      <td>(47755)</td>\n",
       "      <td>0.146993</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.016609</td>\n",
       "      <td>0.112990</td>\n",
       "      <td>2.054395</td>\n",
       "      <td>0.008524</td>\n",
       "      <td>1.065378</td>\n",
       "      <td>0.601682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(47755)</td>\n",
       "      <td>(24848)</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.146993</td>\n",
       "      <td>0.016609</td>\n",
       "      <td>0.301982</td>\n",
       "      <td>2.054395</td>\n",
       "      <td>0.008524</td>\n",
       "      <td>1.222042</td>\n",
       "      <td>0.543109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(21899)</td>\n",
       "      <td>(21133)</td>\n",
       "      <td>0.075251</td>\n",
       "      <td>0.082331</td>\n",
       "      <td>0.011862</td>\n",
       "      <td>0.157630</td>\n",
       "      <td>1.914594</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>1.089390</td>\n",
       "      <td>0.516568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(21133)</td>\n",
       "      <td>(21899)</td>\n",
       "      <td>0.082331</td>\n",
       "      <td>0.075251</td>\n",
       "      <td>0.011862</td>\n",
       "      <td>0.144074</td>\n",
       "      <td>1.914594</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>1.080408</td>\n",
       "      <td>0.520554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(13172)</td>\n",
       "      <td>(21133)</td>\n",
       "      <td>0.118030</td>\n",
       "      <td>0.082331</td>\n",
       "      <td>0.019170</td>\n",
       "      <td>0.162414</td>\n",
       "      <td>1.972702</td>\n",
       "      <td>0.009452</td>\n",
       "      <td>1.095612</td>\n",
       "      <td>0.559067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(21133)</td>\n",
       "      <td>(13172)</td>\n",
       "      <td>0.082331</td>\n",
       "      <td>0.118030</td>\n",
       "      <td>0.019170</td>\n",
       "      <td>0.232837</td>\n",
       "      <td>1.972702</td>\n",
       "      <td>0.009452</td>\n",
       "      <td>1.149652</td>\n",
       "      <td>0.537319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(27960)</td>\n",
       "      <td>(13172)</td>\n",
       "      <td>0.042632</td>\n",
       "      <td>0.118030</td>\n",
       "      <td>0.012599</td>\n",
       "      <td>0.295519</td>\n",
       "      <td>2.503775</td>\n",
       "      <td>0.007567</td>\n",
       "      <td>1.251944</td>\n",
       "      <td>0.627348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(13172)</td>\n",
       "      <td>(27960)</td>\n",
       "      <td>0.118030</td>\n",
       "      <td>0.042632</td>\n",
       "      <td>0.012599</td>\n",
       "      <td>0.106741</td>\n",
       "      <td>2.503775</td>\n",
       "      <td>0.007567</td>\n",
       "      <td>1.071770</td>\n",
       "      <td>0.680979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(13172)</td>\n",
       "      <td>(47198)</td>\n",
       "      <td>0.118030</td>\n",
       "      <td>0.066436</td>\n",
       "      <td>0.019391</td>\n",
       "      <td>0.164293</td>\n",
       "      <td>2.472945</td>\n",
       "      <td>0.011550</td>\n",
       "      <td>1.117095</td>\n",
       "      <td>0.675333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(47198)</td>\n",
       "      <td>(13172)</td>\n",
       "      <td>0.066436</td>\n",
       "      <td>0.118030</td>\n",
       "      <td>0.019391</td>\n",
       "      <td>0.291880</td>\n",
       "      <td>2.472945</td>\n",
       "      <td>0.011550</td>\n",
       "      <td>1.245511</td>\n",
       "      <td>0.638011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(24848)</td>\n",
       "      <td>(16793)</td>\n",
       "      <td>0.146993</td>\n",
       "      <td>0.044466</td>\n",
       "      <td>0.012825</td>\n",
       "      <td>0.087251</td>\n",
       "      <td>1.962229</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>1.046876</td>\n",
       "      <td>0.574879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(16793)</td>\n",
       "      <td>(24848)</td>\n",
       "      <td>0.044466</td>\n",
       "      <td>0.146993</td>\n",
       "      <td>0.012825</td>\n",
       "      <td>0.288434</td>\n",
       "      <td>1.962229</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>1.198775</td>\n",
       "      <td>0.513195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(21899)</td>\n",
       "      <td>(13172)</td>\n",
       "      <td>0.075251</td>\n",
       "      <td>0.118030</td>\n",
       "      <td>0.015668</td>\n",
       "      <td>0.208217</td>\n",
       "      <td>1.764107</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.113904</td>\n",
       "      <td>0.468388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(13172)</td>\n",
       "      <td>(21899)</td>\n",
       "      <td>0.118030</td>\n",
       "      <td>0.075251</td>\n",
       "      <td>0.015668</td>\n",
       "      <td>0.132750</td>\n",
       "      <td>1.764107</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.066301</td>\n",
       "      <td>0.491106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(24848)</td>\n",
       "      <td>(21133)</td>\n",
       "      <td>0.146993</td>\n",
       "      <td>0.082331</td>\n",
       "      <td>0.017468</td>\n",
       "      <td>0.118832</td>\n",
       "      <td>1.443353</td>\n",
       "      <td>0.005365</td>\n",
       "      <td>1.041424</td>\n",
       "      <td>0.360101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(21133)</td>\n",
       "      <td>(24848)</td>\n",
       "      <td>0.082331</td>\n",
       "      <td>0.146993</td>\n",
       "      <td>0.017468</td>\n",
       "      <td>0.212163</td>\n",
       "      <td>1.443353</td>\n",
       "      <td>0.005365</td>\n",
       "      <td>1.082720</td>\n",
       "      <td>0.334727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(21133)</td>\n",
       "      <td>(47198)</td>\n",
       "      <td>0.082331</td>\n",
       "      <td>0.066436</td>\n",
       "      <td>0.012689</td>\n",
       "      <td>0.154124</td>\n",
       "      <td>2.319880</td>\n",
       "      <td>0.007219</td>\n",
       "      <td>1.103665</td>\n",
       "      <td>0.619987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(47198)</td>\n",
       "      <td>(21133)</td>\n",
       "      <td>0.066436</td>\n",
       "      <td>0.082331</td>\n",
       "      <td>0.012689</td>\n",
       "      <td>0.190997</td>\n",
       "      <td>2.319880</td>\n",
       "      <td>0.007219</td>\n",
       "      <td>1.134322</td>\n",
       "      <td>0.609431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(24848)</td>\n",
       "      <td>(21899)</td>\n",
       "      <td>0.146993</td>\n",
       "      <td>0.075251</td>\n",
       "      <td>0.015987</td>\n",
       "      <td>0.108758</td>\n",
       "      <td>1.445272</td>\n",
       "      <td>0.004925</td>\n",
       "      <td>1.037596</td>\n",
       "      <td>0.361180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(21899)</td>\n",
       "      <td>(24848)</td>\n",
       "      <td>0.075251</td>\n",
       "      <td>0.146993</td>\n",
       "      <td>0.015987</td>\n",
       "      <td>0.212445</td>\n",
       "      <td>1.445272</td>\n",
       "      <td>0.004925</td>\n",
       "      <td>1.083108</td>\n",
       "      <td>0.333159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(24848)</td>\n",
       "      <td>(47615)</td>\n",
       "      <td>0.146993</td>\n",
       "      <td>0.047485</td>\n",
       "      <td>0.012716</td>\n",
       "      <td>0.086507</td>\n",
       "      <td>1.821783</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>1.042717</td>\n",
       "      <td>0.528820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(47615)</td>\n",
       "      <td>(24848)</td>\n",
       "      <td>0.047485</td>\n",
       "      <td>0.146993</td>\n",
       "      <td>0.012716</td>\n",
       "      <td>0.267790</td>\n",
       "      <td>1.821783</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>1.164975</td>\n",
       "      <td>0.473575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   antecedents consequents  antecedent support  consequent support   support  \\\n",
       "0      (24848)     (47755)            0.146993            0.054999  0.016609   \n",
       "1      (47755)     (24848)            0.054999            0.146993  0.016609   \n",
       "2      (21899)     (21133)            0.075251            0.082331  0.011862   \n",
       "3      (21133)     (21899)            0.082331            0.075251  0.011862   \n",
       "4      (13172)     (21133)            0.118030            0.082331  0.019170   \n",
       "5      (21133)     (13172)            0.082331            0.118030  0.019170   \n",
       "6      (27960)     (13172)            0.042632            0.118030  0.012599   \n",
       "7      (13172)     (27960)            0.118030            0.042632  0.012599   \n",
       "8      (13172)     (47198)            0.118030            0.066436  0.019391   \n",
       "9      (47198)     (13172)            0.066436            0.118030  0.019391   \n",
       "10     (24848)     (16793)            0.146993            0.044466  0.012825   \n",
       "11     (16793)     (24848)            0.044466            0.146993  0.012825   \n",
       "12     (21899)     (13172)            0.075251            0.118030  0.015668   \n",
       "13     (13172)     (21899)            0.118030            0.075251  0.015668   \n",
       "14     (24848)     (21133)            0.146993            0.082331  0.017468   \n",
       "15     (21133)     (24848)            0.082331            0.146993  0.017468   \n",
       "16     (21133)     (47198)            0.082331            0.066436  0.012689   \n",
       "17     (47198)     (21133)            0.066436            0.082331  0.012689   \n",
       "18     (24848)     (21899)            0.146993            0.075251  0.015987   \n",
       "19     (21899)     (24848)            0.075251            0.146993  0.015987   \n",
       "20     (24848)     (47615)            0.146993            0.047485  0.012716   \n",
       "21     (47615)     (24848)            0.047485            0.146993  0.012716   \n",
       "\n",
       "    confidence      lift  leverage  conviction  zhangs_metric  \n",
       "0     0.112990  2.054395  0.008524    1.065378       0.601682  \n",
       "1     0.301982  2.054395  0.008524    1.222042       0.543109  \n",
       "2     0.157630  1.914594  0.005666    1.089390       0.516568  \n",
       "3     0.144074  1.914594  0.005666    1.080408       0.520554  \n",
       "4     0.162414  1.972702  0.009452    1.095612       0.559067  \n",
       "5     0.232837  1.972702  0.009452    1.149652       0.537319  \n",
       "6     0.295519  2.503775  0.007567    1.251944       0.627348  \n",
       "7     0.106741  2.503775  0.007567    1.071770       0.680979  \n",
       "8     0.164293  2.472945  0.011550    1.117095       0.675333  \n",
       "9     0.291880  2.472945  0.011550    1.245511       0.638011  \n",
       "10    0.087251  1.962229  0.006289    1.046876       0.574879  \n",
       "11    0.288434  1.962229  0.006289    1.198775       0.513195  \n",
       "12    0.208217  1.764107  0.006787    1.113904       0.468388  \n",
       "13    0.132750  1.764107  0.006787    1.066301       0.491106  \n",
       "14    0.118832  1.443353  0.005365    1.041424       0.360101  \n",
       "15    0.212163  1.443353  0.005365    1.082720       0.334727  \n",
       "16    0.154124  2.319880  0.007219    1.103665       0.619987  \n",
       "17    0.190997  2.319880  0.007219    1.134322       0.609431  \n",
       "18    0.108758  1.445272  0.004925    1.037596       0.361180  \n",
       "19    0.212445  1.445272  0.004925    1.083108       0.333159  \n",
       "20    0.086507  1.821783  0.005736    1.042717       0.528820  \n",
       "21    0.267790  1.821783  0.005736    1.164975       0.473575  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Add supporting functions here\n",
    "###  min execution\n",
    "\n",
    "from mlxtend.frequent_patterns import association_rules, fpmax\n",
    "\n",
    "FI_apriori = apriori(binary_database, min_support=0.011, use_colnames=False)\n",
    "FI_apriori_len = FI_apriori.copy()\n",
    "\n",
    "FI_apriori_len['length'] = FI_apriori_len['itemsets'].apply(lambda x: len(x))\n",
    "FI_apriori_len = FI_apriori_len.sort_values(by=['length'], ascending=False)\n",
    "\n",
    "print(FI_apriori_len)\n",
    "\n",
    "all_rules = association_rules(df=FI_apriori_len, metric=\"confidence\", min_threshold=0.05)\n",
    "all_rules\n",
    "\n",
    "\n",
    "# FI_fpmax=fpmax(binary_database, min_support=0.05, use_colnames=False)\n",
    "# FI_fpmax\n",
    "\n",
    "\n",
    "# Trans_maximal = pyeclat(orders.values(), 0.05, target=\"m\")\n",
    "# print(\"Number of Maximal Itemsets\", len(Trans_maximal))\n",
    "# Trans_maximal\n",
    "\n",
    "\n",
    "# Trans_closed = pyeclat(binary_database, 0.05, target=\"c\")\n",
    "# print(\"Number of Closed Itemsets\", len(Trans_closed))\n",
    "# Trans_closed\n",
    "\n",
    "# display_side_by_side(all_rules, FI_fpmax, Trans_maximal, Trans_closed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "999f0f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>zhangs_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(24848)</td>\n",
       "      <td>(47755)</td>\n",
       "      <td>0.146993</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.016609</td>\n",
       "      <td>0.112990</td>\n",
       "      <td>2.054395</td>\n",
       "      <td>0.008524</td>\n",
       "      <td>1.065378</td>\n",
       "      <td>0.601682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(47755)</td>\n",
       "      <td>(24848)</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.146993</td>\n",
       "      <td>0.016609</td>\n",
       "      <td>0.301982</td>\n",
       "      <td>2.054395</td>\n",
       "      <td>0.008524</td>\n",
       "      <td>1.222042</td>\n",
       "      <td>0.543109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(24848)</td>\n",
       "      <td>(21899)</td>\n",
       "      <td>0.146993</td>\n",
       "      <td>0.075251</td>\n",
       "      <td>0.015987</td>\n",
       "      <td>0.108758</td>\n",
       "      <td>1.445272</td>\n",
       "      <td>0.004925</td>\n",
       "      <td>1.037596</td>\n",
       "      <td>0.361180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(21899)</td>\n",
       "      <td>(24848)</td>\n",
       "      <td>0.075251</td>\n",
       "      <td>0.146993</td>\n",
       "      <td>0.015987</td>\n",
       "      <td>0.212445</td>\n",
       "      <td>1.445272</td>\n",
       "      <td>0.004925</td>\n",
       "      <td>1.083108</td>\n",
       "      <td>0.333159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(24848)</td>\n",
       "      <td>(21133)</td>\n",
       "      <td>0.146993</td>\n",
       "      <td>0.082331</td>\n",
       "      <td>0.017468</td>\n",
       "      <td>0.118832</td>\n",
       "      <td>1.443353</td>\n",
       "      <td>0.005365</td>\n",
       "      <td>1.041424</td>\n",
       "      <td>0.360101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(21133)</td>\n",
       "      <td>(24848)</td>\n",
       "      <td>0.082331</td>\n",
       "      <td>0.146993</td>\n",
       "      <td>0.017468</td>\n",
       "      <td>0.212163</td>\n",
       "      <td>1.443353</td>\n",
       "      <td>0.005365</td>\n",
       "      <td>1.082720</td>\n",
       "      <td>0.334727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(13172)</td>\n",
       "      <td>(47198)</td>\n",
       "      <td>0.118030</td>\n",
       "      <td>0.066436</td>\n",
       "      <td>0.019391</td>\n",
       "      <td>0.164293</td>\n",
       "      <td>2.472945</td>\n",
       "      <td>0.011550</td>\n",
       "      <td>1.117095</td>\n",
       "      <td>0.675333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(47198)</td>\n",
       "      <td>(13172)</td>\n",
       "      <td>0.066436</td>\n",
       "      <td>0.118030</td>\n",
       "      <td>0.019391</td>\n",
       "      <td>0.291880</td>\n",
       "      <td>2.472945</td>\n",
       "      <td>0.011550</td>\n",
       "      <td>1.245511</td>\n",
       "      <td>0.638011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(21899)</td>\n",
       "      <td>(13172)</td>\n",
       "      <td>0.075251</td>\n",
       "      <td>0.118030</td>\n",
       "      <td>0.015668</td>\n",
       "      <td>0.208217</td>\n",
       "      <td>1.764107</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.113904</td>\n",
       "      <td>0.468388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(13172)</td>\n",
       "      <td>(21899)</td>\n",
       "      <td>0.118030</td>\n",
       "      <td>0.075251</td>\n",
       "      <td>0.015668</td>\n",
       "      <td>0.132750</td>\n",
       "      <td>1.764107</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.066301</td>\n",
       "      <td>0.491106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(13172)</td>\n",
       "      <td>(21133)</td>\n",
       "      <td>0.118030</td>\n",
       "      <td>0.082331</td>\n",
       "      <td>0.019170</td>\n",
       "      <td>0.162414</td>\n",
       "      <td>1.972702</td>\n",
       "      <td>0.009452</td>\n",
       "      <td>1.095612</td>\n",
       "      <td>0.559067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(21133)</td>\n",
       "      <td>(13172)</td>\n",
       "      <td>0.082331</td>\n",
       "      <td>0.118030</td>\n",
       "      <td>0.019170</td>\n",
       "      <td>0.232837</td>\n",
       "      <td>1.972702</td>\n",
       "      <td>0.009452</td>\n",
       "      <td>1.149652</td>\n",
       "      <td>0.537319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   antecedents consequents  antecedent support  consequent support   support  \\\n",
       "0      (24848)     (47755)            0.146993            0.054999  0.016609   \n",
       "1      (47755)     (24848)            0.054999            0.146993  0.016609   \n",
       "2      (24848)     (21899)            0.146993            0.075251  0.015987   \n",
       "3      (21899)     (24848)            0.075251            0.146993  0.015987   \n",
       "4      (24848)     (21133)            0.146993            0.082331  0.017468   \n",
       "5      (21133)     (24848)            0.082331            0.146993  0.017468   \n",
       "6      (13172)     (47198)            0.118030            0.066436  0.019391   \n",
       "7      (47198)     (13172)            0.066436            0.118030  0.019391   \n",
       "8      (21899)     (13172)            0.075251            0.118030  0.015668   \n",
       "9      (13172)     (21899)            0.118030            0.075251  0.015668   \n",
       "10     (13172)     (21133)            0.118030            0.082331  0.019170   \n",
       "11     (21133)     (13172)            0.082331            0.118030  0.019170   \n",
       "\n",
       "    confidence      lift  leverage  conviction  zhangs_metric  \n",
       "0     0.112990  2.054395  0.008524    1.065378       0.601682  \n",
       "1     0.301982  2.054395  0.008524    1.222042       0.543109  \n",
       "2     0.108758  1.445272  0.004925    1.037596       0.361180  \n",
       "3     0.212445  1.445272  0.004925    1.083108       0.333159  \n",
       "4     0.118832  1.443353  0.005365    1.041424       0.360101  \n",
       "5     0.212163  1.443353  0.005365    1.082720       0.334727  \n",
       "6     0.164293  2.472945  0.011550    1.117095       0.675333  \n",
       "7     0.291880  2.472945  0.011550    1.245511       0.638011  \n",
       "8     0.208217  1.764107  0.006787    1.113904       0.468388  \n",
       "9     0.132750  1.764107  0.006787    1.066301       0.491106  \n",
       "10    0.162414  1.972702  0.009452    1.095612       0.559067  \n",
       "11    0.232837  1.972702  0.009452    1.149652       0.537319  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "FI_fpmax = fpmax(binary_database, min_support=0.05, use_colnames=False)\n",
    "FI_fpmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c7bf182",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FI_fpmax' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mFI_fpmax\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'FI_fpmax' is not defined"
     ]
    }
   ],
   "source": [
    "Trans_maximal = pyeclat(orders.values(), 0.05, target=\"m\")\n",
    "print(\"Number of Maximal Itemsets\", len(Trans_maximal))\n",
    "Trans_maximal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c83e5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054999</td>\n",
       "      <td>(47766,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066436</td>\n",
       "      <td>(47209,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.075251</td>\n",
       "      <td>(21903,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.082331</td>\n",
       "      <td>(21137,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.118030</td>\n",
       "      <td>(13176,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.146993</td>\n",
       "      <td>(24852,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    support  itemsets\n",
       "0  0.054999  (47766,)\n",
       "1  0.066436  (47209,)\n",
       "2  0.075251  (21903,)\n",
       "3  0.082331  (21137,)\n",
       "4  0.118030  (13176,)\n",
       "5  0.146993  (24852,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trans_maximal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a7f54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050889</td>\n",
       "      <td>(-, i, e,  )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.050929</td>\n",
       "      <td>(-, i, e)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.052600</td>\n",
       "      <td>(-, i,  )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.052660</td>\n",
       "      <td>(-, i)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.050385</td>\n",
       "      <td>(-, r, a,  )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142209</th>\n",
       "      <td>0.903658</td>\n",
       "      <td>(a,  )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142210</th>\n",
       "      <td>0.911408</td>\n",
       "      <td>(a,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142211</th>\n",
       "      <td>0.926002</td>\n",
       "      <td>(e,  )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142212</th>\n",
       "      <td>0.933390</td>\n",
       "      <td>(e,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142213</th>\n",
       "      <td>0.986976</td>\n",
       "      <td>( ,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142214 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         support      itemsets\n",
       "0       0.050889  (-, i, e,  )\n",
       "1       0.050929     (-, i, e)\n",
       "2       0.052600     (-, i,  )\n",
       "3       0.052660        (-, i)\n",
       "4       0.050385  (-, r, a,  )\n",
       "...          ...           ...\n",
       "142209  0.903658        (a,  )\n",
       "142210  0.911408          (a,)\n",
       "142211  0.926002        (e,  )\n",
       "142212  0.933390          (e,)\n",
       "142213  0.986976          ( ,)\n",
       "\n",
       "[142214 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trans_closed = pyeclat(binary_database, 0.05, target=\"c\")\n",
    "print(\"Number of Closed Itemsets\", len(Trans_closed))\n",
    "Trans_closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603d0a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   antecedents consequents  antecedent support  consequent support   support  \\\n",
      "0          ( )         (i)                 NaN                 NaN  0.821004   \n",
      "1          (i)         ( )                 NaN                 NaN  0.821004   \n",
      "2          ( )         (r)                 NaN                 NaN  0.834974   \n",
      "3          (r)         ( )                 NaN                 NaN  0.834974   \n",
      "4       ( , e)         (a)                 NaN                 NaN  0.850937   \n",
      "5       ( , a)         (e)                 NaN                 NaN  0.850937   \n",
      "6       (e, a)         ( )                 NaN                 NaN  0.850937   \n",
      "7          ( )      (e, a)                 NaN                 NaN  0.850937   \n",
      "8          (e)      ( , a)                 NaN                 NaN  0.850937   \n",
      "9          (a)      ( , e)                 NaN                 NaN  0.850937   \n",
      "10         (e)         (a)                 NaN                 NaN  0.855144   \n",
      "11         (a)         (e)                 NaN                 NaN  0.855144   \n",
      "12         ( )         (a)                 NaN                 NaN  0.903658   \n",
      "13         (a)         ( )                 NaN                 NaN  0.903658   \n",
      "14         ( )         (e)                 NaN                 NaN  0.926002   \n",
      "15         (e)         ( )                 NaN                 NaN  0.926002   \n",
      "\n",
      "    confidence  lift  leverage  conviction  zhangs_metric  \n",
      "0          NaN   NaN       NaN         NaN            NaN  \n",
      "1          NaN   NaN       NaN         NaN            NaN  \n",
      "2          NaN   NaN       NaN         NaN            NaN  \n",
      "3          NaN   NaN       NaN         NaN            NaN  \n",
      "4          NaN   NaN       NaN         NaN            NaN  \n",
      "5          NaN   NaN       NaN         NaN            NaN  \n",
      "6          NaN   NaN       NaN         NaN            NaN  \n",
      "7          NaN   NaN       NaN         NaN            NaN  \n",
      "8          NaN   NaN       NaN         NaN            NaN  \n",
      "9          NaN   NaN       NaN         NaN            NaN  \n",
      "10         NaN   NaN       NaN         NaN            NaN  \n",
      "11         NaN   NaN       NaN         NaN            NaN  \n",
      "12         NaN   NaN       NaN         NaN            NaN  \n",
      "13         NaN   NaN       NaN         NaN            NaN  \n",
      "14         NaN   NaN       NaN         NaN            NaN  \n",
      "15         NaN   NaN       NaN         NaN            NaN  \n",
      "Empty DataFrame\n",
      "Columns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction, zhangs_metric]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "closed_itemsets = association_rules(Trans_closed, metric=\"support\", min_threshold=0.8, support_only=True)\n",
    "maximal_itemsets = association_rules(Trans_maximal, metric=\"support\", min_threshold=0.8, support_only=False)\n",
    "\n",
    "print(closed_itemsets)\n",
    "print(maximal_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad80328c-ffba-4bb6-8ce3-03726ee82348",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m### Add processing code here\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#generated by using ChatGPT\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Get closed and maximal itemsets using association_rules\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m closed_itemsets \u001b[38;5;241m=\u001b[39m \u001b[43massociation_rules\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTrans_closed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msupport\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.02\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msupport_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m maximal_itemsets \u001b[38;5;241m=\u001b[39m association_rules(Trans_maximal, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupport\u001b[39m\u001b[38;5;124m\"\u001b[39m, min_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.02\u001b[39m, support_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#generated by using ChatGPT\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\joaom\\Documents\\FCUL\\2ºSemestre\\Prospeção_de_Dados(Data_Mining)\\TP2024\\.venv\\Lib\\site-packages\\mlxtend\\frequent_patterns\\association_rules.py:196\u001b[0m, in \u001b[0;36massociation_rules\u001b[1;34m(df, metric, min_threshold, support_only)\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;66;03m# check for the threshold\u001b[39;00m\n\u001b[0;32m    195\u001b[0m score \u001b[38;5;241m=\u001b[39m metric_dict[metric](sAC, sA, sC)\n\u001b[1;32m--> 196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m score \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m min_threshold:\n\u001b[0;32m    197\u001b[0m     rule_antecedents\u001b[38;5;241m.\u001b[39mappend(antecedent)\n\u001b[0;32m    198\u001b[0m     rule_consequents\u001b[38;5;241m.\u001b[39mappend(consequent)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Add processing code here\n",
    "\n",
    "#generated by using ChatGPT\n",
    "# Get closed and maximal itemsets using association_rules\n",
    "closed_itemsets = association_rules(Trans_closed, metric=\"support\", min_threshold=0.02, support_only=True)\n",
    "maximal_itemsets = association_rules(Trans_maximal, metric=\"support\", min_threshold=0.02, support_only=False)\n",
    "\n",
    "#generated by using ChatGPT\n",
    "rules_closed = association_rules(closed_itemsets, metric=\"lift\", min_threshold=1)\n",
    "rules_maximal = association_rules(maximal_itemsets, metric=\"confidence\", min_threshold=0.2)\n",
    "\n",
    "#generated by using ChatGPT\n",
    "# Sort the rules by confidence and Lift\n",
    "rules_closed = rules_closed.sort_values([\"confidence\", \"lift\"], ascending=[False, False])\n",
    "rules_maximal = rules_maximal.sort_values([\"confidence\", \"lift\"], ascending=[False, False])\n",
    "\n",
    "# Filter the rules with minimum confidence and Lift\n",
    "min_confidence = 0.8\n",
    "min_lift = 1.5\n",
    "rules_closed = rules_closed[(rules_closed[\"confidence\"] >= min_confidence) & (rules_closed[\"lift\"] >= min_lift) ]\n",
    "rules_maximal = rules_maximal[(rules_maximal[\"confidence\"] >= min_confidence) & (rules_maximal[\"lift\"] >= min_lift)]\n",
    "\n",
    "print(rules_closed)\n",
    "print(rules_maximal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322a87b8-4102-43ff-ac7c-e748df7bcd1f",
   "metadata": {},
   "source": [
    "### Your short analysis here\n",
    "\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
